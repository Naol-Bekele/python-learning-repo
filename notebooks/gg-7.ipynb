{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Chapter 13:üåê HTTP & API Fundamentals\n",
    "\n",
    "Welcome to this comprehensive guide on HTTP protocols and API interactions! This notebook covers everything from basic requests to advanced API features with practical examples you can run yourself.\n",
    "\n",
    "## üìö What You'll Learn\n",
    "- HTTP request/response cycle\n",
    "- Working with REST APIs\n",
    "- Authentication methods\n",
    "- Error handling and rate limiting\n",
    "- Real-time data collection\n",
    "- Combining APIs with web scraping\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "http-basics",
   "metadata": {},
   "source": [
    "## üîó HTTP Basics & First API Call\n",
    "\n",
    "HTTP (HyperText Transfer Protocol) is the foundation of data communication on the web. APIs (Application Programming Interfaces) allow different software systems to communicate with each other using HTTP protocols.\n",
    "\n",
    "### HTTP Methods Overview:\n",
    "- **GET**: Retrieve data from server\n",
    "- **POST**: Send data to server\n",
    "- **PUT**: Update existing resource\n",
    "- **DELETE**: Remove resource\n",
    "\n",
    "Let's make our first API call to a jokes API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "first-api-call",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Status Meaning: ‚úÖ Success\n",
      "\n",
      "üìù Joke: Bad at golf?\n",
      "üé≠ Punchline: Join the club.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Example: Get a random joke from the \"Official Joke API\"\n",
    "url = \"https://official-joke-api.appspot.com/random_joke\"\n",
    "response = requests.get(url)  # Send GET request\n",
    "\n",
    "# Check status code (200 means success)\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Status Meaning:\", \"‚úÖ Success\" if response.status_code == 200 else \"‚ùå Error\")\n",
    "\n",
    "# Get JSON data\n",
    "data = response.json()\n",
    "print(\"\\nüìù Joke:\", data['setup'])\n",
    "print(\"üé≠ Punchline:\", data['punchline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-response-types",
   "metadata": {},
   "source": [
    "## üìä Understanding API Responses\n",
    "\n",
    "APIs can return different data formats. The most common are:\n",
    "\n",
    "1. **JSON** (JavaScript Object Notation) - Most common for APIs\n",
    "2. **XML** (Extensible Markup Language) - Older but still used\n",
    "3. **Plain Text** - Simple responses\n",
    "\n",
    "Let's explore another API that returns JSON data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dog-api-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Full Response: {'message': 'https://images.dog.ceo/breeds/greyhound-italian/n02091032_6037.jpg', 'status': 'success'}\n",
      "üê∂ Random Dog Image URL: https://images.dog.ceo/breeds/greyhound-italian/n02091032_6037.jpg\n",
      "Request Status: success\n"
     ]
    }
   ],
   "source": [
    "# Dog CEO API - Get random dog images\n",
    "import requests\n",
    "\n",
    "url = \"https://dog.ceo/api/breeds/image/random\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Full Response:\", data)\n",
    "print(\"üê∂ Random Dog Image URL:\", data[\"message\"])\n",
    "print(\"Request Status:\", data[\"status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-parameters",
   "metadata": {},
   "source": [
    "## üîß Working with API Parameters\n",
    "\n",
    "Most APIs accept parameters to customize responses. Parameters can be:\n",
    "- Added directly to the URL: `?key=value&another=value`\n",
    "- Passed as a dictionary in `requests.get()`\n",
    "\n",
    "### Example: Getting Multiple Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üêï Dog Images URLs:\n",
      "1. https://images.dog.ceo/breeds/pointer-germanlonghair/hans2.jpg\n",
      "2. https://images.dog.ceo/breeds/groenendael/n02105056_7381.jpg\n",
      "3. https://images.dog.ceo/breeds/mastiff-bull/n02108422_1939.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Get 3 dog images instead of just 1\n",
    "url = \"https://dog.ceo/api/breeds/image/random/3\"\n",
    "response = requests.get(url)\n",
    "\n",
    "data = response.json()\n",
    "print(\"üêï Dog Images URLs:\")\n",
    "for i, img_url in enumerate(data['message'], 1):\n",
    "    print(f\"{i}. {img_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pagination",
   "metadata": {},
   "source": [
    "## üìë Pagination\n",
    "\n",
    "Many APIs limit how much data they return at once and use pagination to split results across multiple pages.\n",
    "\n",
    "### Example: Working with Paginated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pagination-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Page 1 Results:\n",
      "Post 1: sunt aut facere repellat provident occaecati excepturi optio reprehenderit\n",
      "Post 2: qui est esse\n",
      "Post 3: ea molestias quasi exercitationem repellat qui ipsa sit aut\n",
      "Post 4: eum et est occaecati\n",
      "Post 5: nesciunt quas odio\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "params = {\"_page\": 1, \"_limit\": 5}  # Page 1, 5 results per page\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "print(f\"üìÑ Page {params['_page']} Results:\")\n",
    "for post in data:\n",
    "    print(f\"Post {post['id']}: {post['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentication",
   "metadata": {},
   "source": [
    "## üîê API Authentication\n",
    "\n",
    "Many APIs require authentication to control access and track usage. Common methods:\n",
    "\n",
    "1. **API Keys** - Simple token added to requests\n",
    "2. **OAuth** - Secure authorization framework\n",
    "3. **Bearer Tokens** - Token-based authentication\n",
    "\n",
    "### Example: Using an API Key (OpenWeatherMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "weather-api-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: Invalid API key. Please see https://openweathermap.org/faq#error401 for more info.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = \"Your api key\"  # Example key (replace with your own)\n",
    "url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "params = {\"q\": \"London\", \"appid\": API_KEY, \"units\": \"metric\"}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"üå§Ô∏è Weather in {data['name']}:\")\n",
    "    print(f\"Temperature: {data['main']['temp']}¬∞C\")\n",
    "    print(f\"Conditions: {data['weather'][0]['description']}\")\n",
    "    print(f\"Humidity: {data['main']['humidity']}%\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {data.get('message', 'Unknown error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error-handling",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Error Handling & Rate Limiting\n",
    "\n",
    "APIs can fail for various reasons. Proper error handling ensures your application remains stable.\n",
    "\n",
    "### Common API Errors:\n",
    "- `400 Bad Request` - Invalid parameters\n",
    "- `401 Unauthorized` - Invalid or missing authentication\n",
    "- `403 Forbidden` - Authenticated but not authorized\n",
    "- `404 Not Found` - Resource doesn't exist\n",
    "- `429 Too Many Requests` - Rate limit exceeded\n",
    "- `500 Internal Server Error` - Server-side issue\n",
    "\n",
    "### Example: Comprehensive Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "error-handling-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success:\n",
      "1. Unlike dogs, cats do not have a sweet tooth. Scientists believe this is due to a mutation in a key taste receptor.\n",
      "2. When a cat chases its prey, it keeps its head level. Dogs and humans bob their heads up and down.\n",
      "3. The technical term for a cat‚Äôs hairball is a ‚Äúbezoar.‚Äù\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://catfact.ninja/facts\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, timeout=5)  # 5 second timeout\n",
    "    response.raise_for_status()  # Raise error for bad status codes (4xx/5xx)\n",
    "    \n",
    "    data = response.json()\n",
    "    print(\"‚úÖ Success:\")\n",
    "    for i, fact in enumerate(data['data'][:3], 1):  # Show first 3 facts\n",
    "        print(f\"{i}. {fact['fact']}\")\n",
    "        \n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"‚è≥ Request timed out\")\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"‚ùå HTTP Error: {e}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ö†Ô∏è Other Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rate-limiting",
   "metadata": {},
   "source": [
    "## üö¶ Rate Limiting\n",
    "\n",
    "APIs often limit how many requests you can make to prevent abuse. Always check the API documentation for rate limits.\n",
    "\n",
    "### Example: Respecting Rate Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rate-limiting-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 1...\n",
      "Request 2...\n",
      "Request 3...\n",
      "\n",
      "üìã Collected 30 cat facts!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "facts = []\n",
    "url = \"https://catfact.ninja/facts\"\n",
    "\n",
    "for i in range(3):  # Make 3 requests\n",
    "    print(f\"Request {i+1}...\")\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        facts.extend([item['fact'] for item in data['data']])\n",
    "    else:\n",
    "        print(f\"Error on request {i+1}: {response.status_code}\")\n",
    "    \n",
    "    time.sleep(1)  # Wait 1 second between requests\n",
    "\n",
    "print(f\"\\nüìã Collected {len(facts)} cat facts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "building-datasets",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Building Datasets from APIs\n",
    "\n",
    "APIs are excellent sources for creating datasets. Let's build a dataset of cat facts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f726e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Page 1: Collected 10 facts so far.\n",
      "üìÑ Page 2: Collected 20 facts so far.\n",
      "üìÑ Page 3: Collected 30 facts so far.\n",
      "üìÑ Page 4: Collected 40 facts so far.\n",
      "üìÑ Page 5: Collected 50 facts so far.\n",
      "‚úÖ Saved 50 cat facts to cat_facts.csv\n",
      "\n",
      "Sample facts:\n",
      "                                                                                                                                          fact\n",
      "                            Unlike dogs, cats do not have a sweet tooth. Scientists believe this is due to a mutation in a key taste receptor.\n",
      "                                             When a cat chases its prey, it keeps its head level. Dogs and humans bob their heads up and down.\n",
      "                                                                                        The technical term for a cat‚Äôs hairball is a ‚Äúbezoar.‚Äù\n",
      "                                                                                                        A group of cats is called a ‚Äúclowder.‚Äù\n",
      "A cat can‚Äôt climb head first down a tree because every claw on a cat‚Äôs paw points the same way. To get down from a tree, a cat must back down.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "def fetch_cat_facts(goal_facts=50):\n",
    "    \"\"\"\n",
    "    Fetches a specified number of cat facts from the Cat Fact API.\n",
    "    \"\"\"\n",
    "    facts_list = []\n",
    "    url = \"https://catfact.ninja/facts\"\n",
    "    page = 1\n",
    "    \n",
    "    while len(facts_list) < goal_facts:\n",
    "        params = {\"limit\": 10, \"page\": page}\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            response.raise_for_status()  # Raises HTTPError for bad responses (4xx or 5xx)\n",
    "            data = response.json()\n",
    "            \n",
    "            # Check for data\n",
    "            if not data.get('data'):\n",
    "                print(\"No more facts available.\")\n",
    "                break\n",
    "                \n",
    "            facts = [fact.get('fact') for fact in data['data']]\n",
    "            facts_list.extend(facts)\n",
    "            \n",
    "            print(f\"üìÑ Page {page}: Collected {len(facts_list)} facts so far.\")\n",
    "            \n",
    "            # Check if we've reached the last page to avoid unnecessary requests\n",
    "            if page >= data.get('last_page', page):\n",
    "                print(\"Reached the last page of facts on the API.\")\n",
    "                break\n",
    "            \n",
    "            page += 1\n",
    "            time.sleep(1)  # Respect API rate limits\n",
    "            \n",
    "        except RequestException as e:\n",
    "            print(f\"An error occurred on page {page}: {e}\")\n",
    "            break\n",
    "        except KeyError as e:\n",
    "            print(f\"JSON parsing error: Missing key {e} on page {page}.\")\n",
    "            break\n",
    "            \n",
    "    return facts_list\n",
    "\n",
    "def save_facts_to_csv(facts, filename=\"cat_facts.csv\"):\n",
    "    \"\"\"\n",
    "    Saves a list of facts to a CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(facts, columns=[\"fact\"])\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"‚úÖ Saved {len(df)} cat facts to {filename}\")\n",
    "    print(\"\\nSample facts:\")\n",
    "    print(df.head().to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    collected_facts = fetch_cat_facts(goal_facts=50)\n",
    "    save_facts_to_csv(collected_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real-time-apis",
   "metadata": {},
   "source": [
    "## ‚ö° Real-Time API Data\n",
    "\n",
    "Some APIs provide real-time or frequently updated data. Let's track cryptocurrency prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "crypto-tracking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Starting crypto price tracking...\n",
      "Press Ctrl+C to stop\n",
      "\n",
      "2025-08-30 18:46:53 | BTC: $108916 | ETH: $4377.5\n",
      "2025-08-30 18:46:58 | BTC: $108916 | ETH: $4377.5\n",
      "2025-08-30 18:47:03 | BTC: $108916 | ETH: $4377.5\n",
      "2025-08-30 18:47:08 | BTC: $108916 | ETH: $4377.5\n",
      "2025-08-30 18:47:13 | BTC: $108916 | ETH: $4377.5\n",
      "\n",
      "‚úÖ Saved 5 records to crypto_prices.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "url = \"https://api.coingecko.com/api/v3/simple/price\"\n",
    "params = {\"ids\": \"bitcoin,ethereum\", \"vs_currencies\": \"usd\"}\n",
    "records = []\n",
    "\n",
    "print(\"üìä Starting crypto price tracking...\")\n",
    "print(\"Press Ctrl+C to stop\\n\")\n",
    "\n",
    "try:\n",
    "    for i in range(5):  # Get 5 readings\n",
    "        response = requests.get(url, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            btc_price = data['bitcoin']['usd']\n",
    "            eth_price = data['ethereum']['usd']\n",
    "            \n",
    "            print(f\"{timestamp} | BTC: ${btc_price} | ETH: ${eth_price}\")\n",
    "            \n",
    "            records.append({\n",
    "                \"timestamp\": timestamp,\n",
    "                \"btc_usd\": btc_price,\n",
    "                \"eth_usd\": eth_price\n",
    "            })\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è API Error: {response.status_code}\")\n",
    "        \n",
    "        time.sleep(5)  # Wait 5 seconds between requests\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "\n",
    "# Save to CSV\n",
    "if records:\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(\"crypto_prices.csv\", index=False)\n",
    "    print(f\"\\n‚úÖ Saved {len(df)} records to crypto_prices.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-scraping-hybrid",
   "metadata": {},
   "source": [
    "## ü§ù API + Web Scraping Hybrid\n",
    "\n",
    "Sometimes you need to combine API data with web scraping to get complete information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd990bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 18:48:51,989 - INFO - ‚úÖ Collected from API: Nearside of the Moon\n",
      "2025-08-30 18:48:52,570 - INFO - ‚úÖ Collected from API: Color of the Moon\n",
      "2025-08-30 18:48:53,073 - INFO - ‚úÖ Collected from API: Moon to Mars Transportation and Habitation\n",
      "2025-08-30 18:48:53,576 - INFO - ‚úÖ Collected from API: Moon to Mars Multidisciplinary Science\n",
      "2025-08-30 18:48:54,079 - INFO - ‚úÖ Collected from API: Moon to Mars Infrastructure\n",
      "2025-08-30 18:48:54,596 - INFO - \n",
      "üìä Saved 5 records to nasa_images.csv\n",
      "2025-08-30 18:48:54,605 - INFO - \n",
      "Sample data:\n",
      "                                     title                                                                                                                                   url                                                                                                                                                                                                 description\n",
      "                      Nearside of the Moon                                                                     https://images-assets.nasa.gov/image/PIA12235/PIA12235~medium.jpg                                                                                                                                                                                        Nearside of the Moon\n",
      "                         Color of the Moon                                                                      https://images-assets.nasa.gov/image/PIA13517/PIA13517~small.jpg                                                                                                                                                                                           Color of the Moon\n",
      "Moon to Mars Transportation and Habitation https://images-assets.nasa.gov/image/Moon to Mars Transportation and Habitation/Moon to Mars Transportation and Habitation~medium.jpg This illustration of Moon to Mars transportation and habitation shows astronauts driving a pressurized rover away from the dome of a translucent lunar habitat. NASA‚Äôs Moon to Mars Objectives establish...\n",
      "    Moon to Mars Multidisciplinary Science         https://images-assets.nasa.gov/image/Moon to Mars Multidisciplinary Science/Moon to Mars Multidisciplinary Science~medium.jpg This illustration of Moon to Mars multidisciplinary science shows astronauts collecting and analyzing lunar regolith. NASA‚Äôs Moon to Mars Objectives establish an objectives-based approach to the agenc...\n",
      "               Moon to Mars Infrastructure                               https://images-assets.nasa.gov/image/Moon to Mars Infrastructure/Moon to Mars Infrastructure~medium.jpg This illustration of Moon to Mars infrastructure shows astronauts living and working on the surface of Mars. NASA‚Äôs Moon to Mars Objectives establish an objectives-based approach to the agency's human...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.exceptions import RequestException\n",
    "import logging\n",
    "\n",
    "# Configure basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "NASA_API_URL = \"https://images-api.nasa.gov/search\"\n",
    "\n",
    "def get_image_details(session, item_data, nasa_url):\n",
    "    \"\"\"\n",
    "    Scrapes a specific NASA page for a description.\n",
    "    Uses the session object to reuse connections.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        page_response = session.get(nasa_url, timeout=10)\n",
    "        page_response.raise_for_status()\n",
    "        soup = BeautifulSoup(page_response.text, \"html.parser\")\n",
    "        \n",
    "        description = \"No description found\"\n",
    "        # Try to find description in common meta tags or elements\n",
    "        meta_desc = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "        if meta_desc:\n",
    "            description = meta_desc.get(\"content\", \"No description found\")\n",
    "        \n",
    "        # Consider an alternative search if meta tag is not present\n",
    "        if description == \"No description found\":\n",
    "            # Example of trying to find it in a different element\n",
    "            p_desc = soup.find(\"p\", class_=\"description-class-here\") # Replace with actual class\n",
    "            if p_desc:\n",
    "                description = p_desc.text.strip()\n",
    "                \n",
    "        # Truncate and clean description\n",
    "        clean_desc = description.replace(\"\\n\", \" \").strip()\n",
    "        final_description = (clean_desc[:200] + \"...\") if len(clean_desc) > 200 else clean_desc\n",
    "        \n",
    "        return final_description\n",
    "    except RequestException as e:\n",
    "        logging.error(f\"Failed to scrape {nasa_url}: {e}\")\n",
    "        return \"Scraping failed.\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the data collection and saving.\n",
    "    \"\"\"\n",
    "    params = {\"q\": \"moon\", \"media_type\": \"image\"}\n",
    "    records = []\n",
    "    \n",
    "    try:\n",
    "        # Use a session for persistent connections\n",
    "        with requests.Session() as session:\n",
    "            response = session.get(NASA_API_URL, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            items = data.get('collection', {}).get('items', [])\n",
    "            \n",
    "            # Use enumerate for a clearer loop with an index\n",
    "            for i, item in enumerate(items[:5]): # Use a reasonable limit\n",
    "                # Safely get data using .get() to prevent errors\n",
    "                item_data = item.get('data', [{}])[0]\n",
    "                title = item_data.get('title', 'No Title')\n",
    "                nasa_url = item.get('links', [{}])[0].get('href', None)\n",
    "                \n",
    "                # Check if we can get description directly from API\n",
    "                api_description = item_data.get('description', None)\n",
    "                if api_description:\n",
    "                    description = (api_description[:200] + \"...\") if len(api_description) > 200 else api_description\n",
    "                    logging.info(f\"‚úÖ Collected from API: {title}\")\n",
    "                elif nasa_url:\n",
    "                    # If not, scrape the individual page\n",
    "                    description = get_image_details(session, item_data, nasa_url)\n",
    "                    logging.info(f\"‚úÖ Scraped details for: {title}\")\n",
    "                else:\n",
    "                    description = \"No URL found\"\n",
    "                    logging.warning(f\"Item {i+1} has no URL.\")\n",
    "                \n",
    "                records.append({\n",
    "                    \"title\": title,\n",
    "                    \"url\": nasa_url,\n",
    "                    \"description\": description\n",
    "                })\n",
    "                \n",
    "                time.sleep(0.5) # Be polite to the server with a short delay\n",
    "\n",
    "    except RequestException as e:\n",
    "        logging.error(f\"An error occurred during API call: {e}\")\n",
    "        return\n",
    "    except (KeyError, IndexError) as e:\n",
    "        logging.error(f\"Failed to parse JSON response: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    if records:\n",
    "        df = pd.DataFrame(records)\n",
    "        df.to_csv(\"nasa_images.csv\", index=False)\n",
    "        logging.info(f\"\\nüìä Saved {len(df)} records to nasa_images.csv\")\n",
    "        logging.info(\"\\nSample data:\\n\" + df.head().to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practice-exercises",
   "metadata": {},
   "source": [
    "## üß™ Practice Exercises\n",
    "\n",
    "### Exercise 1: Basic API Call\n",
    "Create a program that fetches 5 random dog images and prints their URLs.\n",
    "\n",
    "### Exercise 2: Error Handling\n",
    "Modify the weather API example to handle these error scenarios:\n",
    "- Invalid city name\n",
    "Invalid API key\n",
    "- Network timeout\n",
    "\n",
    "### Exercise 3: Data Collection\n",
    "Create a dataset of 30 facts from the Cat Facts API with proper pagination handling.\n",
    "\n",
    "### Exercise 4: Real-time Monitoring\n",
    "Create a program that tracks cryptocurrency prices every 10 seconds for 1 minute and calculates the average price for each coin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "main-challenge",
   "metadata": {},
   "source": [
    "## üèÜ Main Challenge: API Dashboard\n",
    "\n",
    "Create a simple dashboard that displays:\n",
    "1. Current weather in 3 cities of your choice\n",
    "2. 5 random cat facts\n",
    "3. Current prices of Bitcoin and Ethereum\n",
    "4. A random dog image\n",
    "\n",
    "**Bonus:** \n",
    "- Add error handling for all API calls\n",
    "- Implement a refresh button to update all data\n",
    "- Save the collected data to files with timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion\n",
    "\n",
    "You've learned how to:\n",
    "- Make HTTP requests to various APIs\n",
    "- Handle different response formats and status codes\n",
    "- Work with API parameters and pagination\n",
    "- Implement authentication and rate limiting\n",
    "- Build datasets from API data\n",
    " Combine APIs with web scraping\n",
    "- Create real-time data collection systems\n",
    "\n",
    "### üìö Further Learning\n",
    "- Explore API documentation for services you use\n",
    "- Learn about OAuth authentication\n",
    "- Experiment with WebSockets for real-time communication\n",
    "- Try building a frontend interface for your API calls\n",
    "\n",
    "Happy coding! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
